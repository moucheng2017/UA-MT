GPU Prolog Script v1.10
This is a GPU node.
Enough GPUs available.
Allocating card 0
Namespace(root_path='../data/2018LA_Seg_Training Set/', exp='Mismatch_unlabel', max_iterations=6000, batch_size=4, width=8, labeled_bs=1, base_lr=0.01, deterministic=1, seed=1337, gpu='0', consistency_type='mse', consistency=0.01, consistency_rampup=40.0, labels=2, threshold=0.0)
Traceback (most recent call last):
  File "/SAN/medic/PerceptronHead/codes/UA-MT/code/train_LA_mismatch_unlabel_mask.py", line 115, in <module>
    model = create_model()
  File "/SAN/medic/PerceptronHead/codes/UA-MT/code/train_LA_mismatch_unlabel_mask.py", line 109, in create_model
    model = net.cuda()
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 680, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/mouchexu/miniconda3/envs/pytorch1.4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 680, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
GPU Epilog Script v0.30
